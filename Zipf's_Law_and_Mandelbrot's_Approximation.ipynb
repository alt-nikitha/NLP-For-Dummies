{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zipf's Law and Mandelbrot's Approximation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPJ2fqtIUrvEYTcOLWJg4n5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alt-nikitha/NLP-For-Dummies/blob/master/Zipf's_Law_and_Mandelbrot's_Approximation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0FXYwTnKIEu",
        "colab_type": "text"
      },
      "source": [
        "Zipf's law states that the term frequency is inversely proportional to its rank in the frequency table. This means that if the most common word in the text makes up 7% of the table, the second most common word will make up half of 7% which is 3.5%, the third most common will make up one-third of 7% which is 2.3% and so on. This means that the product of the rank and the term frequency is almost constant, approximately equal to the term frequency of the most common word. For actual texts it is not entirely linear as described. But let us see how this works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwYaDX3BKHtS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLM6BGfPRNTF",
        "colab_type": "text"
      },
      "source": [
        "Now let us generate the frequency table for the top 10 words in some sample text. For more details about its generation, go through the term frequency notebook in the repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9AxLfXcB_uL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5238ee2a-50cd-48a0-c704-314c6a39b80d"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY_7MyeyRgGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words=set(stopwords.words('english'))\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzGGPgO0Rmk4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "be3a8504-687c-4c3b-e1fd-2c10c9766cbd"
      },
      "source": [
        "nltk.download('gutenberg')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_M0OBquRndl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "73dce595-4da0-4042-c2ee-6941bd5f8e70"
      },
      "source": [
        "words=nltk.Text(nltk.corpus.gutenberg.words('bryant-stories.txt'))\n",
        "words=[word.lower() for word in words if(word.isalpha())]\n",
        "words=[word.lower() for word in words if(word not in stop_words)]\n",
        "fDist=FreqDist(words)\n",
        "\n",
        "print(len(words))\n",
        "print(len(set(words)))\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21718\n",
            "3688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVcwCvauTIv0",
        "colab_type": "text"
      },
      "source": [
        "The frequency table thus has the words in the order of occurrence, the frequency of the words, the proportion of the text that they make up, and the product of term frequency and rank, which is the constant of proportionality in Zipf's law."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSfZu8tfRriJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "35460483-fdaf-4c7c-f244-fd49225ba21f"
      },
      "source": [
        "i=1\n",
        "for x,v in fDist.most_common(10):\n",
        "  print(x,v,v/len(fDist),v*i)\n",
        "  i+=1\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "little 597 0.1618763557483731 597\n",
            "said 453 0.12283080260303687 906\n",
            "came 191 0.05178958785249458 573\n",
            "one 183 0.04962039045553145 732\n",
            "could 158 0.042841648590021694 790\n",
            "king 141 0.038232104121475055 846\n",
            "went 122 0.03308026030368764 854\n",
            "would 112 0.03036876355748373 896\n",
            "great 110 0.02982646420824295 990\n",
            "day 107 0.02901301518438178 1070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM7dPzJpTZfB",
        "colab_type": "text"
      },
      "source": [
        "We see that it is not exactly linear but it is true for the words in the mid frequency range where the product lies in the 800s range. Since this does not accurately describe the relationship between the term frequency and rank, another law was developed called the Mandelbrot Approximation. This added another constant beta to the rank. The value of this constant was approximated to around 2.7. Let's see if this law holds for the text we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL7qXNX_TEAK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e7dbee37-bb97-41b5-bf7e-43cb1e1d008c"
      },
      "source": [
        "i=1\n",
        "for x,v in fDist.most_common(10):\n",
        "  print(x,v,v/len(fDist),v*(i+2.7))\n",
        "  i+=1"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "little 597 0.1618763557483731 2208.9\n",
            "said 453 0.12283080260303687 2129.1\n",
            "came 191 0.05178958785249458 1088.7\n",
            "one 183 0.04962039045553145 1226.1000000000001\n",
            "could 158 0.042841648590021694 1216.6000000000001\n",
            "king 141 0.038232104121475055 1226.6999999999998\n",
            "went 122 0.03308026030368764 1183.3999999999999\n",
            "would 112 0.03036876355748373 1198.3999999999999\n",
            "great 110 0.02982646420824295 1287.0\n",
            "day 107 0.02901301518438178 1358.8999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B443VdtUZ1T",
        "colab_type": "text"
      },
      "source": [
        "Now we see that there is more uniformity in the product, especially in the mid frequency range. So we can see that for this text, the mandelbort's approximation seems to fit the word frequencies better than Zipf's law."
      ]
    }
  ]
}