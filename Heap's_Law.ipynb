{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Heap's Law.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNQTkA41n8wj8tUowV3Usvo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alt-nikitha/NLP-For-Dummies/blob/master/Heap's_Law.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhdIv6pxpj1_",
        "colab_type": "text"
      },
      "source": [
        "Here, we'll be looking at heap's law, which seems like a fairly obvious law. This states that the vocabulary used in a piece of text is proportional to its length. The slightly more precise relation is that M=K*(T^b), where 30<=k<=100, and b is approximately 0.49."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWv4xaIuCT4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4KHl3RrCq-Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ebc28169-6453-4d38-93ad-40246a616238"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNltLzOKCwAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words=set(stopwords.words('english'))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R-i4MpaCyKS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b18cc44f-884c-48f4-e776-392de934da50"
      },
      "source": [
        "nltk.download('gutenberg')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGhIC2sTqMJA",
        "colab_type": "text"
      },
      "source": [
        "We will compare two pieces of text again to make sure that our results aren't random. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqI6ZCWLCz9a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d6f6f562-0b27-4f04-832e-fb2622d9d217"
      },
      "source": [
        "words_emma=nltk.Text(nltk.corpus.gutenberg.words('austen-emma.txt'))\n",
        "words_emma=[word.lower() for word in words_emma if(word.isalpha())]\n",
        "words_emma=[word.lower() for word in words_emma if(word not in stop_words)]\n",
        "fDist=FreqDist(words_emma)\n",
        "\n",
        "print(len(words_emma))\n",
        "print(len(set(words_emma)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73149\n",
            "6948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD0fLgZlC6u3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b4b057ed-c27b-41ef-aedb-095c584be12c"
      },
      "source": [
        "words_bryant=nltk.Text(nltk.corpus.gutenberg.words('bryant-stories.txt'))\n",
        "words_bryant=[word.lower() for word in words_bryant if(word.isalpha())]\n",
        "words_bryant=[word.lower() for word in words_bryant if(word not in stop_words)]\n",
        "fDist=FreqDist(words_bryant)\n",
        "\n",
        "print(len(words_bryant))\n",
        "print(len(set(words_bryant)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21718\n",
            "3688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB7g3gGMqUxM",
        "colab_type": "text"
      },
      "source": [
        "After preprocessing, we calculate the constant of proportionality K from Heap's law for both these texts. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O_gRSW8DT_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "heaps_bryant=len(set(words_bryant))/(pow(len(words_bryant),0.49))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyj3uTTqDv5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "heaps_emma=len(set(words_emma))/(pow(len(words_emma),0.49))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPYi3QwrD0sr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae957412-21fa-4773-8d7b-4af81d7bc157"
      },
      "source": [
        "print(heaps_bryant)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27.65344206431527\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd-klEEnD3BX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c84cc03d-53e9-4a87-bb62-75dd5214eb2e"
      },
      "source": [
        "print(heaps_emma)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28.734106494814665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf0jZtWJqeoQ",
        "colab_type": "text"
      },
      "source": [
        "We see that both constants are very close to each other and sorta verify Heap's Law. Plus they are close to 30 which seems to be the lower limit of K."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgmOC2tSq2Ig",
        "colab_type": "text"
      },
      "source": [
        "In general, the significance of Heap's law is to say that the vocabulary never maxes out, and always increase, as you increase the number of documents in consideration. "
      ]
    }
  ]
}